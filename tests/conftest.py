"""
pytest configuration and fixtures for PTO testing framework.
"""

import sys
from pathlib import Path

import pytest

# Add framework src path first
_FRAMEWORK_ROOT = Path(__file__).parent.parent
_SRC_PATH = _FRAMEWORK_ROOT / "src"
if _SRC_PATH.exists() and str(_SRC_PATH) not in sys.path:
    sys.path.insert(0, str(_SRC_PATH))

# Import environment module for path resolution
from pto_test.core import environment

# Add dependency paths using environment module
_PYPTO_PYTHON = environment.get_pypto_python_path()
_SIMPLER_PYTHON = environment.get_simpler_python_path()
_SIMPLER_SCRIPTS = environment.get_simpler_scripts_path()

for path in [_PYPTO_PYTHON, _SIMPLER_PYTHON, _SIMPLER_SCRIPTS]:
    if path is not None and path.exists() and str(path) not in sys.path:
        sys.path.insert(0, str(path))

from pto_test.core.test_case import TestConfig
from pto_test.core.test_runner import TestRunner


def pytest_addoption(parser):
    """Add custom command line options."""
    parser.addoption(
        "--platform",
        action="store",
        default="a2a3sim",
        choices=["a2a3sim", "a2a3"],
        help="Target platform for tests (default: a2a3sim)",
    )
    parser.addoption(
        "--device",
        action="store",
        default=0,
        type=int,
        help="Device ID for hardware tests (default: 0)",
    )
    parser.addoption(
        "--strategy",
        action="store",
        default="Default",
        choices=["Default", "PTOAS"],
        help="Optimization strategy for PyPTO pass pipeline (default: Default)",
    )
    parser.addoption(
        "--fuzz-count",
        action="store",
        default=10,
        type=int,
        help="Number of fuzz test iterations (default: 10)",
    )
    parser.addoption(
        "--fuzz-seed",
        action="store",
        default=None,
        type=int,
        help="Random seed for fuzz tests (default: random)",
    )
    parser.addoption(
        "--kernels-dir",
        action="store",
        default=None,
        help="Output directory for generated kernels (default: build/outputs/output_{timestamp}/)",
    )
    parser.addoption(
        "--save-kernels",
        action="store_true",
        default=False,
        help="Save generated kernels to --kernels-dir (default: False)",
    )
    parser.addoption(
        "--dump-passes",
        action="store_true",
        default=False,
        help="Dump intermediate IR after each pass (default: False)",
    )
    parser.addoption(
        "--codegen-only",
        action="store_true",
        default=False,
        help="Only generate code, skip runtime execution (default: False)",
    )


@pytest.fixture(scope="session")
def test_config(request) -> TestConfig:
    """Session-scoped fixture providing test configuration from CLI options.

    Session scope means the config is created once and shared across all tests,
    which is appropriate since CLI options don't change during a test run.
    """
    # Determine save_kernels_dir
    save_kernels = request.config.getoption("--save-kernels")
    save_kernels_dir = None
    if save_kernels:
        kernels_dir = request.config.getoption("--kernels-dir")
        # If --kernels-dir is specified, use it; otherwise None will use session output directory
        save_kernels_dir = kernels_dir

    return TestConfig(
        platform=request.config.getoption("--platform"),
        device_id=request.config.getoption("--device"),
        save_kernels=save_kernels,
        save_kernels_dir=save_kernels_dir,
        dump_passes=request.config.getoption("--dump-passes"),
        codegen_only=request.config.getoption("--codegen-only"),
    )


@pytest.fixture(scope="session")
def test_runner(test_config) -> TestRunner:
    """Session-scoped fixture providing a test runner instance.

    Session scope is used because:
    1. The runner caches compiled runtime binaries
    2. Building the runtime takes significant time
    3. The same runner can be reused across all tests
    """
    return TestRunner(test_config)


@pytest.fixture
def optimization_strategy(request) -> str:
    """Fixture providing the optimization strategy from CLI options."""
    return request.config.getoption("--strategy")


@pytest.fixture
def fuzz_count(request) -> int:
    """Fixture providing fuzz test iteration count."""
    return request.config.getoption("--fuzz-count")


@pytest.fixture
def fuzz_seed(request) -> int:
    """Fixture providing fuzz test seed."""
    seed = request.config.getoption("--fuzz-seed")
    if seed is None:
        import random

        seed = random.randint(0, 2**31 - 1)
    return seed


# Standard test shapes for parameterized tests
STANDARD_SHAPES = [
    (64, 64),
    (128, 128),
    (256, 256),
]


@pytest.fixture(params=STANDARD_SHAPES)
def tensor_shape(request):
    """Parameterized fixture for tensor shapes."""
    return list(request.param)


# Skip markers
def pytest_configure(config):
    """Register custom markers."""
    config.addinivalue_line(
        "markers", "hardware: mark test as requiring hardware (--platform=a2a3)"
    )
    config.addinivalue_line("markers", "slow: mark test as slow")
    config.addinivalue_line("markers", "fuzz: mark test as fuzz test")


def pytest_collection_modifyitems(config, items):
    """Modify test collection based on platform."""
    platform = config.getoption("--platform")

    skip_hardware = pytest.mark.skip(reason="hardware tests require --platform=a2a3")

    for item in items:
        if "hardware" in item.keywords and platform != "a2a3":
            item.add_marker(skip_hardware)
